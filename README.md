# ğŸš€ I/O Performance Comparison: Python vs Go vs Kotlin

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![Go](https://img.shields.io/badge/Go-1.19+-00ADD8.svg)](https://golang.org/dl/)
[![Kotlin](https://img.shields.io/badge/Kotlin-JVM-7F52FF.svg)](https://kotlinlang.org/)

A comprehensive benchmarking suite that compares file I/O performance across Python, Go, and Kotlin implementations. This project provides detailed performance analysis with statistical rigor and beautiful visualizations.

## âœ¨ Features

- ğŸ”„ **Multi-language benchmarking**: Tests Python, Go, and Kotlin I/O performance
- ğŸ“Š **Multiple file sizes**: Tests with 1MB, 10MB, 50MB, and 100MB files
- ğŸ“ˆ **Statistical analysis**: Multiple iterations with mean, median, min, max, and standard deviation
- ğŸ“‰ **Visual comparisons**: Generates performance charts and graphs
- âš¡ **Throughput metrics**: Measures MB/s for read and write operations
- ğŸ¤– **Automated execution**: Single command runs all benchmarks
- ğŸ”§ **Cross-platform**: Works on macOS, Linux, and Windows

## ğŸ“ Project Structure

```
â”œâ”€â”€ benchmark_runner.py      # ğŸ¯ Main benchmark orchestrator
â”œâ”€â”€ quick_test.py            # ğŸ§ª Quick implementation tester
â”œâ”€â”€ test_setup.py           # âš™ï¸ Setup verification script
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ io_benchmark.py     # ğŸ Python I/O implementation
â”‚   â””â”€â”€ io_test.py          # ğŸ Python test runner
â”œâ”€â”€ golang/
â”‚   â”œâ”€â”€ main.go             # ğŸ¹ Go I/O implementation
â”‚   â””â”€â”€ go.mod              # ğŸ¹ Go module definition
â”œâ”€â”€ kotlin/
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ src/main/kotlin/org/example/
â”‚           â””â”€â”€ App.kt      # ğŸ¯ Kotlin I/O implementation
â”œâ”€â”€ data/                   # ğŸ“‚ Test files (auto-generated)
â”œâ”€â”€ results/                # ğŸ“Š Benchmark results (auto-generated)
â”œâ”€â”€ Makefile               # ğŸ”¨ Build and run commands
â”œâ”€â”€ requirements.txt       # ğŸ“¦ Python dependencies
â””â”€â”€ .gitignore             # ğŸš« Git ignore rules
```

## ğŸš€ Quick Start

### Prerequisites

- ğŸ **Python 3.7+**
- ğŸ¹ **Go 1.19+**
- â˜• **Java 11+** (for Kotlin)
- ğŸ”¨ **Make** (build automation)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/io-performance-comparison.git
   cd io-performance-comparison
   ```

2. **Install dependencies** (creates Python virtual environment automatically)
   ```bash
   make install-deps
   ```

> **ğŸ’¡ Note**: On macOS/Linux, this automatically creates a Python virtual environment to avoid conflicts with system Python packages.

### ğŸƒâ€â™‚ï¸ Running Benchmarks

**Run the complete benchmark suite:**
```bash
make benchmark
```

**Test individual implementations:**
```bash
make test-individual
```

**Quick verification test:**
```bash
python3 quick_test.py
```

**Run specific language tests:**
```bash
make run-python    # ğŸ Python only
make run-go        # ğŸ¹ Go only
make run-kotlin    # Kotlin only
```

## Benchmark Details

### Test Operations

1. **Write Test**: Copy a test file using 8KB buffer chunks
2. **Read Test**: Read the copied file using 8KB buffer chunks

### File Sizes Tested

- 1 MB
- 10 MB
- 50 MB
- 100 MB

### Metrics Collected

- **Execution Time**: Time taken for read/write operations
- **Throughput**: MB/s for each operation
- **Statistical Analysis**: Mean, median, min, max, standard deviation
- **Relative Performance**: Performance ratios compared to Go baseline

### ğŸ“Š Sample Results

Here's what you can expect from the benchmark results:

| Language | File Size | Read (MB/s) | Write (MB/s) |
|----------|-----------|-------------|--------------|
| Go       | 100MB     | 3,856       | 815          |
| Kotlin   | 100MB     | 4,054       | 802          |
| Python   | 100MB     | 4,054       | 805          |

*Results may vary based on hardware and system configuration*

### ğŸ“ Output Files

After running benchmarks, check the `results/` directory:

- ğŸ“„ `benchmark_results.json`: Raw benchmark data with all iterations
- ğŸ“Š `benchmark_summary.csv`: Tabulated results with statistics
- ğŸ“ˆ `io_performance_comparison.png`: Performance visualization charts

## ğŸ”§ Implementation Details

### ğŸ Python Implementation
- Uses built-in `open()` with binary mode
- 8KB buffer size for chunked I/O
- Context managers for proper file handling
- JSON output for benchmark results

### ğŸ¹ Go Implementation  
- Uses `os.Open()` and `os.Create()`
- 8KB byte slice buffer
- Proper error handling and resource cleanup
- Structured JSON output with custom types

### ğŸ¯ Kotlin Implementation
- Uses `FileInputStream`/`FileOutputStream`
- 8KB ByteArray buffer
- Automatic resource management with `use{}`
- Gson for JSON serialization

## Performance Expectations

Typical performance characteristics:

- **Go**: Generally fastest, especially for large files
- **Kotlin**: Close to Go performance, benefits from JVM optimizations
- **Python**: Slower for pure I/O, but difference narrows with larger files

Results vary based on:

- Hardware (SSD vs HDD, CPU, RAM)
- Operating system
- File system type
- System load

## Customization

### Modify Test Parameters

Edit `benchmark_runner.py`:

```python
self.test_file_sizes = [1, 10, 50, 100]  # File sizes in MB
self.iterations = 3                       # Number of test runs
```

### Change Buffer Size

Update buffer size in each implementation:

- Python: `chunk = f_in.read(8192)`
- Go: `buf := make([]byte, 8192)`
- Kotlin: `val buffer = ByteArray(8192)`

## Troubleshooting

### Common Issues

1. **Missing dependencies**: Run `make install-deps`
2. **Permission errors**: Ensure write access to project directory
3. **Out of disk space**: Large test files require sufficient free space
4. **Java/Kotlin build errors**: Verify Java 11+ is installed

### Clean Up

Remove generated files:

```bash
make clean
```

Remove everything including virtual environment:

```bash
make clean-all
```

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **ğŸ´ Fork the repository**
2. **ğŸŒ¿ Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. **âœ¨ Add your improvements**
   - New language implementations
   - Performance optimizations
   - Better visualizations
   - Bug fixes
4. **ğŸ“ Commit your changes** (`git commit -m 'Add amazing feature'`)
5. **ğŸš€ Push to the branch** (`git push origin feature/amazing-feature`)
6. **ğŸ”„ Submit a pull request**

### Ideas for Contributions
- ğŸ¦€ **Rust implementation**
- ğŸ”· **C# implementation** 
- â˜• **Java implementation**
- ğŸ“Š **More visualization options**
- ğŸ”§ **Different I/O patterns** (async, memory-mapped, etc.)
- ğŸ§ª **Additional test scenarios**

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Thanks to all contributors who help improve this benchmark suite
- Inspired by the need for fair, comprehensive I/O performance comparisons
- Built with â¤ï¸ for the developer community

---

**â­ If this project helped you, please give it a star!**
